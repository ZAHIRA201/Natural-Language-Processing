{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "649e67bf",
   "metadata": {},
   "source": [
    "# PARTIE III"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a794171",
   "metadata": {},
   "source": [
    "# Importation des bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8ad7bc7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils_pos import get_word_tag, preprocess  \n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56955d3e",
   "metadata": {},
   "source": [
    "# Lecture du fichier de vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7a629416",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"fra_mixed-typical_2012_1M-words.txt\", 'r', encoding='utf-8') as f:\n",
    "\n",
    "    vocabulaire = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "68de92f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A few items of the vocabulary list\n",
      "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*']\n",
      "\n",
      "A few items at the end of the vocabulary list\n",
      "['--unk--', '--unk_adj--', '--unk_adv--', '--unk_digit--', '--unk_noun--', '--unk_punct--', '--unk_upper--', '--unk_verb--', '.', '...']\n"
     ]
    }
   ],
   "source": [
    "voca = []\n",
    "\n",
    "# parcourir chaque ligne dans le texte\n",
    "for ligne in vocabulaire:\n",
    "    # diviser la ligne en trois parties et stocker la deuxième partie\n",
    "    deuxieme_partie = ligne.split()[1]\n",
    "    # ajouter la deuxième partie à la liste\n",
    "    voca.append(deuxieme_partie)\n",
    "\n",
    "# afficher la liste des deuxièmes parties\n",
    "\n",
    "print(\"A few items of the vocabulary list\")\n",
    "print(voca[0:10])\n",
    "print()\n",
    "print(\"A few items at the end of the vocabulary list\")\n",
    "print(voca[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cd40986b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298974"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(voca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "271e980b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vous\n"
     ]
    }
   ],
   "source": [
    "print(voca[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d783cf47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268123"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "voca = list(set(voca))\n",
    "len(voca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a804d818",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary dictionary, key is the word, value is a unique integer\n",
      "!:0\n",
      "\":1\n",
      "#:2\n",
      "$:3\n",
      "$.:4\n",
      "$/personne:5\n",
      "$1:6\n",
      "$1000:7\n",
      "$20:8\n",
      "$400:9\n",
      "$500:10\n",
      "$60:11\n",
      "$600:12\n",
      "$800k:13\n",
      "$?:14\n",
      "$content:15\n",
      "$contents:16\n",
      "$lambda$-termes:17\n",
      "$n:18\n",
      "$postpone:19\n",
      "$t:20\n",
      "%:21\n",
      "%!:22\n",
      "%.:23\n",
      "&:24\n",
      "':25\n",
      "(:26\n",
      "):27\n",
      "*:28\n",
      "+:29\n",
      ",:30\n",
      "-:31\n",
      "--:32\n",
      "--n--:33\n",
      "--unk--:34\n",
      "--unk_adj--:35\n",
      "--unk_adv--:36\n",
      "--unk_digit--:37\n",
      "--unk_noun--:38\n",
      "--unk_punct--:39\n",
      "--unk_upper--:40\n",
      "--unk_verb--:41\n",
      ".:42\n",
      "...:43\n",
      "/:44\n",
      "0:45\n",
      "0%:46\n",
      "0''19:47\n",
      "0''7:48\n",
      "0'100:49\n",
      "0,000:50\n"
     ]
    }
   ],
   "source": [
    "# vocab: dictionary that has the index of the corresponding words\n",
    "vocab = {} \n",
    "\n",
    "# Get the index of the corresponding words. \n",
    "for i, word in enumerate(sorted(voca)): \n",
    "    vocab[word] = i       \n",
    "    \n",
    "print(\"Vocabulary dictionary, key is the word, value is a unique integer\")\n",
    "cnt = 0\n",
    "for k,v in vocab.items():\n",
    "    print(f\"{k}:{v}\")\n",
    "    cnt += 1\n",
    "    if cnt > 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ff86fb",
   "metadata": {},
   "source": [
    "# Chargement du corpus d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "931cc33b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A few items of the training corpus list\n",
      "['Nutashkuan_NPP', 'se_CLR', 'sont_V', 'retirées_VPP', 'des_DET', 'négociations_NC', 'territoriales_ADJ', 'avec_P', 'le_DET', 'gouvernement_NC']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2028032"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"tags_train.txt\", 'r', encoding='utf-8') as f:\n",
    "    training = f.read()\n",
    "    training_corpus = training.split()\n",
    "print(f\"A few items of the training corpus list\")\n",
    "print(training_corpus[10:20])\n",
    "len(training_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d375c562",
   "metadata": {},
   "source": [
    "# Nouveau corpus d'entraînement limité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5bbe4d67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33000"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_corpus = training_corpus[0:33000]\n",
    "len(training_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20561b4",
   "metadata": {},
   "source": [
    "# Chargement du corpus de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a1fca254",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sample of the test corpus\n",
      "['Ce_DET', 'vendredi_NC', ',_PONCT', 'quatre_DET', 'matchs_NC', 'de_P', 'la_DET', 'ligue_NC', 'nationale_ADJ', 'de_P']\n"
     ]
    }
   ],
   "source": [
    "with open(\"tags_test.txt\", 'r', encoding='utf-8') as f:\n",
    "    test = f.read()\n",
    "    y = test.split()\n",
    "print(\"A sample of the test corpus\")\n",
    "print(y[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39a658a",
   "metadata": {},
   "source": [
    "# Prétraitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801e8ab4",
   "metadata": {},
   "source": [
    "# preprocess ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b3e79c",
   "metadata": {},
   "source": [
    "prend en entrée un vocabulaire et le chemin du fichier de données à prétraiter. Elle lit les données ligne par ligne à partir du fichier, en les séparant en mots. Pour chaque mot, elle vérifie s'il s'agit de la fin d'une phrase (s'il est vide). Si c'est le cas, elle ajoute \"--n--\" à la liste des mots prétraités prep, qui représente le jeton de fin de phrase. Si le mot n'est pas vide et qu'il n'est pas dans le vocabulaire fourni, elle le remplace par un token inconnu en appelant la fonction assign_unk, puis ajoute ce mot prétraité à la liste prep. Si le mot est présent dans le vocabulaire, elle l'ajoute simplement à la liste prep.\n",
    "\n",
    "La fonction retourne deux listes : orig qui contient les mots d'origine et prep qui contient les mots prétraités. Les assertions à la fin garantissent que le nombre de mots dans les listes originales et prétraitées correspond au nombre de lignes dans le fichier de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6e3303ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the preprocessed test corpus:  507364\n",
      "This is a sample of the test_corpus: \n",
      "['éventuel', '--unk--', 'ou', 'à', 'des', 'escroqueries', '.', 'Bien', 'que', 'Barack', 'Obama', 'ait', 'obtenu', '61', '%', 'des', 'suffrages', 'en', 'ayant', 'rallié', '--unk_punct--', 'appui', 'de', 'la', 'communauté', 'noire', ',', 'Hillary', 'Clinton', 'a', 'rassemblé', '37', '%', 'des', 'votes', 'pour', 'les', '33', 'délégués', 'de', '--unk_punct--', 'état', '.', 'Ce', 'genre', '--unk_punct--', 'action', 'est', 'inédite', 'dans']\n"
     ]
    }
   ],
   "source": [
    "#corpus without tags, preprocessed\n",
    "_, prep = preprocess(vocab, \"words.txt\")     \n",
    "\n",
    "print('The length of the preprocessed test corpus: ', len(prep))\n",
    "print('This is a sample of the test_corpus: ')\n",
    "print(prep[50:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17d2486",
   "metadata": {},
   "source": [
    "# Caractères de ponctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "27ee9cd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string\n",
    "punct = set(string.punctuation)\n",
    "# Règles de morphologie utilisées pour attribuer des jetons de mot inconnu\n",
    "noun_suffix = [\"action\", \"age\", \"ance\", \"cy\", \"dom\", \"ee\", \"ence\", \"er\", \"hood\", \"ion\", \"ism\", \"ist\", \"ity\", \"ling\", \"ment\", \"ness\", \"or\", \"ry\", \"scape\", \"ship\", \"ty\"]\n",
    "verb_suffix = [\"ate\", \"ify\", \"ise\", \"ize\"]\n",
    "adj_suffix = [\"able\", \"ese\", \"ful\", \"i\", \"ian\", \"ible\", \"ic\", \"ish\", \"ive\", \"less\", \"ly\", \"ous\"]\n",
    "adv_suffix = [\"ward\", \"wards\", \"wise\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6a0adf",
   "metadata": {},
   "source": [
    "# Assignation de tokens pour les mots inconnus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2f0dd04e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assign_unk(tok):\n",
    "    \"\"\"\n",
    "    Assign unknown word tokens\n",
    "    \"\"\"\n",
    "    # Digits\n",
    "    if any(char.isdigit() for char in tok):\n",
    "        return \"--unk_digit--\"\n",
    "\n",
    "    # Punctuation\n",
    "    elif any(char in punct for char in tok):\n",
    "        return \"--unk_punct--\"\n",
    "\n",
    "    # Upper-case\n",
    "    elif any(char.isupper() for char in tok):\n",
    "        return \"--unk_upper--\"\n",
    "\n",
    "    # Nouns\n",
    "    elif any(tok.endswith(suffix) for suffix in noun_suffix):\n",
    "        return \"--unk_noun--\"\n",
    "\n",
    "    # Verbs\n",
    "    elif any(tok.endswith(suffix) for suffix in verb_suffix):\n",
    "        return \"--unk_verb--\"\n",
    "\n",
    "    # Adjectives\n",
    "    elif any(tok.endswith(suffix) for suffix in adj_suffix):\n",
    "        return \"--unk_adj--\"\n",
    "\n",
    "    # Adverbs\n",
    "    elif any(tok.endswith(suffix) for suffix in adv_suffix):\n",
    "        return \"--unk_adv--\"\n",
    "\n",
    "    return \"--unk--\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d67aaa",
   "metadata": {},
   "source": [
    "# Extraction des mots et des tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9e9722a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_word_tag(line, vocab):\n",
    "    if not line.strip():\n",
    "        word = \"--n--\"\n",
    "        tag = \"--s--\"\n",
    "    else:\n",
    "        a = line.split(\"_\")\n",
    "        if len(a) == 2:\n",
    "            word, tag = a\n",
    "            if word not in vocab: \n",
    "                word = assign_unk(word)\n",
    "        else:\n",
    "            word = \"--n--\"\n",
    "            tag = \"--s--\"\n",
    "    return word, tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "838ecb30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('se', 'CLR')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_tag('se_CLR', vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8fa59202",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l=[]\n",
    "for word_tag in training_corpus:\n",
    "    a = get_word_tag(word_tag, vocab)\n",
    "    l.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1e6fb58b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('communautés', 'NC'),\n",
       " ('--unk--', 'ADJ'),\n",
       " ('--unk_punct--', 'P'),\n",
       " ('--unk_upper--', 'NPP')]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc17a237",
   "metadata": {},
   "source": [
    "# Création des matrices de transition et d'émission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeafb11",
   "metadata": {},
   "source": [
    "#                                                create_dictionaries ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9d2334",
   "metadata": {},
   "source": [
    "                                            \n",
    "prend en entrée un corpus d'entraînement et un vocabulaire, puis elle crée et renvoie trois dictionnaires : emission_counts, transition_counts, et tag_counts. Ces dictionnaires sont utilisés dans le modèle de Markov caché pour représenter les comptes d'émissions, de transitions et d'étiquettes respectivement. La fonction parcourt chaque paire mot-étiquette dans le corpus d'entraînement, comptant les occurrences de chaque transition, émission et étiquette. Elle renvoie ensuite ces compteurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1c152939",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dictionaries(training_corpus, vocab):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        training_corpus: un corpus où chaque ligne contient un mot suivi de son étiquette.\n",
    "        vocab: un dictionnaire où les clés sont les mots du vocabulaire et la valeur est un indice\n",
    "    Output: \n",
    "        emission_counts: un dictionnaire où les clés sont (étiquette, mot) et les valeurs sont les comptes\n",
    "        transition_counts: un dictionnaire où les clés sont (prev_tag, tag) et les valeurs sont les comptes\n",
    "        tag_counts: un dictionnaire où les clés sont les étiquettes et les valeurs sont les comptes\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialiser les dictionnaires en utilisant defaultdict\n",
    "    emission_counts = defaultdict(int)\n",
    "    transition_counts = defaultdict(int)\n",
    "    tag_counts = defaultdict(int)\n",
    "    \n",
    "    # Initialiser \"prev_tag\" (étiquette précédente) avec l'état de départ, indiqué par '--s--'\n",
    "    prev_tag = '--s--' \n",
    "    \n",
    "    # Utiliser 'i' pour suivre le numéro de ligne dans le corpus\n",
    "    i = 0 \n",
    "    \n",
    "    # Chaque élément dans le corpus d'entraînement contient un mot et son étiquette POS\n",
    "    # Parcourir chaque mot et son étiquette dans le corpus d'entraînement\n",
    "    for word_tag in training_corpus:\n",
    "        \n",
    "        # Incrémenter le compteur de mots et étiquettes\n",
    "        i += 1\n",
    "        \n",
    "        # Tous les 50 000 mots, imprimer le compteur de mots\n",
    "        if i % 50000 == 0:\n",
    "            print(f\"nombre de mots = {i}\")\n",
    "        # Obtenir le mot et l'étiquette en utilisant la fonction d'aide get_word_tag (importée depuis utils_pos.py)\n",
    "        word, tag = get_word_tag(word_tag, vocab) \n",
    "        \n",
    "        # Incrémenter le compteur de transition pour le mot et l'étiquette précédents\n",
    "        transition_counts[(prev_tag, tag)] += 1\n",
    "        \n",
    "        # Incrémenter le compteur d'émission pour l'étiquette et le mot\n",
    "        emission_counts[(tag, word)] += 1\n",
    "\n",
    "        # Incrémenter le compteur d'étiquettes\n",
    "        tag_counts[tag] += 1\n",
    "\n",
    "        # Définir l'étiquette précédente sur cette étiquette (pour la prochaine itération de la boucle)\n",
    "        prev_tag = tag\n",
    "        \n",
    "    return emission_counts, transition_counts, tag_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8c89b94e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emission_counts, transition_counts, tag_counts = create_dictionaries(training_corpus, vocab)\n",
    "a= sorted(emission_counts.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8bcaadc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of POS tags (number of 'states'): 30\n",
      "View these POS tags (states)\n",
      "['--s--', 'ADJ', 'ADJWH', 'ADV', 'ADVWH', 'CC', 'CLO', 'CLR', 'CLS', 'CS', 'DET', 'DETWH', 'ET', 'I', 'NC', 'NPP', 'P', 'P+D', 'PONCT', 'PREF', 'PRO', 'PROREL', 'PROWH', 'U', 'V', 'VIMP', 'VINF', 'VPP', 'VPR', 'VS']\n"
     ]
    }
   ],
   "source": [
    "# get all the POS states\n",
    "states = sorted(tag_counts.keys())\n",
    "print(f\"Number of POS tags (number of 'states'): {len(states)}\")\n",
    "print(\"View these POS tags (states)\")\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9454eb21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transition examples: \n",
      "(('--s--', 'DET'), 1)\n",
      "(('DET', 'NC'), 3895)\n",
      "(('NC', 'ADJ'), 1127)\n",
      "(('ADJ', 'P'), 431)\n",
      "(('P', 'NPP'), 433)\n",
      "(('NPP', 'PONCT'), 821)\n",
      "\n",
      "emission examples: \n",
      "(('ADJ', 'autonome'), 1)\n",
      "(('NC', 'transports'), 3)\n",
      "(('ADJ', 'parisiens'), 1)\n",
      "\n",
      "ambiguous word example: \n"
     ]
    }
   ],
   "source": [
    "print(\"transition examples: \")\n",
    "for ex in list(transition_counts.items())[:6]:\n",
    "    print(ex)\n",
    "print()\n",
    "\n",
    "print(\"emission examples: \")\n",
    "for ex in list(emission_counts.items())[200:203]:\n",
    "    print (ex)\n",
    "print()\n",
    "\n",
    "print(\"ambiguous word example: \")\n",
    "for tup,cnt in emission_counts.items():\n",
    "    if tup[1] == 'you': print (tup, cnt) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d937e0a",
   "metadata": {},
   "source": [
    "#                                               predict_pos ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6150f7e6",
   "metadata": {},
   "source": [
    "                                  \n",
    "prend en entrée une version prétraitée d'un corpus prep, le corpus étiqueté y, un dictionnaire emission_counts contenant les comptes d'émissions, un vocabulaire vocab, et une liste states de toutes les étiquettes possibles. Elle retourne la précision de la prédiction, c'est-à-dire le nombre de fois où un mot a été correctement classé.\n",
    "\n",
    "Elle parcourt chaque mot du corpus prétraité et son étiquette associée. Pour chaque mot, elle vérifie s'il est présent dans le vocabulaire. Si oui, elle trouve le POS prédit avec le plus grand nombre de compte d'émission pour ce mot, en utilisant les informations stockées dans emission_counts. Si le POS prédit correspond au vrai POS, elle incrémente le nombre de prédictions correctes. Enfin, elle calcule et retourne la précision en divisant le nombre de prédictions correctes par le nombre total de mots dans le corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a0ebb737",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_pos(prep, y, emission_counts, vocab, states):\n",
    "    '''\n",
    "    Input: \n",
    "        prep: une version prétraitée de 'y'. Une liste avec le composant 'mot' des tuples.\n",
    "        y: un corpus composé d'une liste de tuples où chaque tuple consiste en (mot, POS)\n",
    "        emission_counts: un dictionnaire où les clés sont des tuples (tag, mot) et la valeur est le compte\n",
    "        vocab: un dictionnaire où les clés sont des mots dans le vocabulaire et la valeur est un indice\n",
    "        states: une liste triée de toutes les étiquettes possibles pour cet exercice\n",
    "    Output: \n",
    "        accuracy: nombre de fois où vous avez classé un mot correctement\n",
    "    '''\n",
    "    \n",
    "   \n",
    "    num_correct = 0\n",
    "    \n",
    "    # Obtenir les tuples (tag, mot), stockés sous forme d'ensemble\n",
    "    all_words = set(emission_counts.keys())\n",
    "    \n",
    "    # Obtenir le nombre de tuples (mot, POS) dans le corpus 'y'\n",
    "    total = len(y)\n",
    "    for word, y_tup in zip(prep, y): \n",
    "        \n",
    "\n",
    "        # Diviser la chaîne (mot, POS) en une liste de deux éléments\n",
    "        y_tup_l = y_tup.split('_')\n",
    "        \n",
    "        # Vérifier que y_tup contient à la fois le mot et le POS\n",
    "        if len(y_tup_l) == 2:\n",
    "            \n",
    "            # Définir l'étiquette POS réelle pour ce mot\n",
    "            true_label = y_tup_l[1]\n",
    "\n",
    "        else:\n",
    "            # Si y_tup ne contient pas le mot et le POS, passer au mot suivant\n",
    "            continue\n",
    "    \n",
    "        count_final = 0\n",
    "        pos_final = ''\n",
    "        \n",
    "        # Si le mot est dans le vocabulaire...\n",
    "        if word in vocab:\n",
    "            for pos in states:\n",
    "                        \n",
    "                # définir la clé comme le tuple contenant le POS et le mot\n",
    "                key = (pos, word)\n",
    "\n",
    "                # vérifier si la clé (pos, mot) existe dans le dictionnaire emission_counts\n",
    "                if key in emission_counts: # compléter cette ligne\n",
    "\n",
    "                # obtenir le compte d'émission du tuple (pos, mot) \n",
    "                    count = emission_counts[key]\n",
    "\n",
    "                    # garder une trace du POS avec le plus grand compte\n",
    "                    if count > count_final: # compléter cette ligne\n",
    "\n",
    "                        # mettre à jour le compteur final (plus grand compte)\n",
    "                        count_final = count\n",
    "\n",
    "                        # mettre à jour le POS final\n",
    "                        pos_final = pos\n",
    "\n",
    "            # Si le POS final (avec le plus grand compte) correspond au vrai POS :\n",
    "            if pos_final == true_label : # compléter cette ligne\n",
    "                \n",
    "                # Mettre à jour le nombre de prédictions correctes\n",
    "                num_correct += 1\n",
    "            \n",
    "  \n",
    "    accuracy = num_correct / total\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7f1bcf54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of prediction using predict_pos is 0.797116074\n"
     ]
    }
   ],
   "source": [
    "accuracy_predict_pos = predict_pos(prep, y, emission_counts, vocab, states)\n",
    "print(f\"Accuracy of prediction using predict_pos is {accuracy_predict_pos:.9f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cb0e6c",
   "metadata": {},
   "source": [
    "# create_transition_matrix ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bdffba",
   "metadata": {},
   "source": [
    "prend en entrée le paramètre de lissage alpha, un dictionnaire tag_counts qui mappe chaque étiquette à son nombre respectif, et un dictionnaire transition_counts contenant les comptes de transition pour les étiquettes précédentes et actuelles. Elle retourne la matrice de transition A.\n",
    "\n",
    "Elle initialise une matrice A de dimensions (num_tags, num_tags) où num_tags est le nombre d'étiquettes POS uniques. Ensuite, elle parcourt chaque paire d'étiquettes POS précédente et actuelle. Pour chaque paire, elle vérifie si elle existe dans les comptes de transition. Si c'est le cas, elle récupère le compte correspondant ; sinon, le compte est initialisé à zéro. Ensuite, elle applique le lissage en utilisant les comptes, alpha, et le nombre total d'étiquettes pour calculer les probabilités de transition et les stocke dans la matrice A. Enfin, elle retourne la matrice de transition ainsi calculée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d3f9a64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transition_matrix(alpha, tag_counts, transition_counts):\n",
    "    ''' \n",
    "    Input: \n",
    "        alpha: nombre utilisé pour le lissage\n",
    "        tag_counts: un dictionnaire qui mappe chaque étiquette à son compte respectif\n",
    "        transition_counts: compte de transition pour le mot et l'étiquette précédents\n",
    "    Output:\n",
    "        A: matrice de dimension (num_tags, num_tags)\n",
    "    '''\n",
    "    # Obtenir une liste triée des étiquettes POS uniques\n",
    "    all_tags = sorted(tag_counts.keys())\n",
    "    \n",
    "    # Compter le nombre d'étiquettes POS uniques\n",
    "    num_tags = len(all_tags)\n",
    "    \n",
    "    # Initialiser la matrice de transition 'A'\n",
    "    A = np.zeros((num_tags, num_tags))\n",
    "    \n",
    "    # Obtenir les tuples de transition uniques (POS précédent, POS actuel)\n",
    "    trans_keys = set(transition_counts.keys())\n",
    "    \n",
    "    # Parcourir chaque ligne de la matrice de transition A\n",
    "    for i in range(num_tags):\n",
    "        \n",
    "        # Parcourir chaque colonne de la matrice de transition A\n",
    "        for j in range(num_tags):\n",
    "\n",
    "            # Initialiser le compteur du (POS précédent, POS actuel) à zéro\n",
    "            count = 0\n",
    "        \n",
    "            # Définir le tuple (POS précédent, POS actuel)\n",
    "            # Obtenir l'étiquette à la position i et l'étiquette à la position j (à partir de la liste all_tags)\n",
    "            key = (all_tags[i], all_tags[j])\n",
    "\n",
    "            # Vérifier si le tuple (POS précédent, POS actuel) \n",
    "            # existe dans le dictionnaire de comptes de transition\n",
    "            if key in transition_counts: # compléter cette ligne\n",
    "                # Obtenir le compte à partir du dictionnaire transition_counts \n",
    "                # pour le tuple (POS précédent, POS actuel)\n",
    "                count = transition_counts[key]\n",
    "                \n",
    "            # Obtenir le compte de l'étiquette précédente (position d'index i) à partir de tag_counts\n",
    "            count_prev_tag = tag_counts[all_tags[i]]\n",
    "            \n",
    "            # Appliquer le lissage en utilisant le compte du tuple, alpha, \n",
    "            # le compte de l'étiquette précédente, alpha, et le nombre total d'étiquettes\n",
    "            A[i, j] = (count + alpha) / (count_prev_tag + alpha * num_tags)\n",
    "    \n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3cdce286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A at row 0, col 0: 0.000970874\n",
      "A at row 3, col 1: 0.0857\n",
      "View a subset of transition matrix A\n",
      "            DET         DETWH        ET             I        NC\n",
      "DET    0.001836  2.039555e-07  0.001836  2.039555e-07  0.794407\n",
      "DETWH  0.000971  9.708738e-04  0.000971  9.708738e-04  0.971845\n",
      "ET     0.006999  6.991540e-06  0.601279  6.991540e-06  0.027973\n",
      "I      0.000330  3.300330e-04  0.000330  3.300330e-04  0.000330\n",
      "NC     0.016346  1.459422e-07  0.000876  1.459422e-07  0.020724\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.001\n",
    "A = create_transition_matrix(alpha, tag_counts, transition_counts)\n",
    "\n",
    "print(f\"A at row 0, col 0: {A[0,0]:.9f}\")\n",
    "print(f\"A at row 3, col 1: {A[3,1]:.4f}\")\n",
    "\n",
    "print(\"View a subset of transition matrix A\")\n",
    "A_sub = pd.DataFrame(A[10:15,10:15], index=states[10:15], columns = states[10:15] )\n",
    "print(A_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06a9702",
   "metadata": {},
   "source": [
    "# create_emission_matrix ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc03bbbc",
   "metadata": {},
   "source": [
    "prend en entrée le paramètre de lissage alpha, un dictionnaire tag_counts qui mappe chaque étiquette à son nombre respectif, un dictionnaire emission_counts où les clés sont des tuples (étiquette, mot) et les valeurs sont les comptes, et un dictionnaire vocab où les clés sont les mots du vocabulaire et la valeur est un index. Elle retourne la matrice d'émission B.\n",
    "\n",
    "Elle initialise une matrice B de dimensions (num_tags, len(vocab)) où num_tags est le nombre d'étiquettes POS uniques et len(vocab) est le nombre total de mots uniques dans le vocabulaire. Ensuite, elle parcourt chaque paire d'étiquette POS et de mot. Pour chaque paire, elle vérifie si elle existe dans les comptes d'émission. Si c'est le cas, elle récupère le compte correspondant ; sinon, le compte est initialisé à zéro. Ensuite, elle applique le lissage en utilisant les comptes, alpha, et le nombre total de mots pour calculer les probabilités d'émission et les stocke dans la matrice B. Enfin, elle retourne la matrice d'émission ainsi calculée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "32a127ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emission_matrix(alpha, tag_counts, emission_counts, vocab):\n",
    "    '''\n",
    "    Input: \n",
    "        alpha: paramètre de réglage utilisé dans le lissage \n",
    "        tag_counts: un dictionnaire qui mappe chaque étiquette à son compte respectif\n",
    "        emission_counts: un dictionnaire où les clés sont (étiquette, mot) et les valeurs sont les comptes\n",
    "        vocab: un dictionnaire où les clés sont les mots du vocabulaire et la valeur est un index\n",
    "    Output:\n",
    "        B: une matrice de dimension (num_tags, len(vocab))\n",
    "    '''  \n",
    "    # obtenir le nombre d'étiquettes POS\n",
    "    num_tags = len(tag_counts)\n",
    "    \n",
    "    # Obtenez une liste de toutes les étiquettes POS\n",
    "    all_tags = sorted(tag_counts.keys())\n",
    "    \n",
    "    # Obtenez le nombre total de mots uniques dans le vocabulaire\n",
    "    num_words = len(vocab)\n",
    "    \n",
    "    # Initialiser la matrice d'émission B avec des emplacements pour\n",
    "    # les étiquettes dans les lignes et les mots dans les colonnes\n",
    "    B = np.zeros((num_tags, num_words))\n",
    "    \n",
    "    # Obtenez un ensemble de tous les tuples (POS, mot) \n",
    "    # à partir des clés du dictionnaire emission_counts\n",
    "    emis_keys = set(list(emission_counts.keys()))\n",
    "    # Parcourir chaque ligne (étiquettes POS)\n",
    "    for i in range(num_tags): # compléter cette ligne\n",
    "        \n",
    "        # Parcourir chaque colonne (mots)\n",
    "        for j in range(num_words): # compléter cette ligne\n",
    "\n",
    "            # Initialiser le compteur d'émission pour le (étiquette POS, mot) à zéro\n",
    "            count = 0\n",
    "                    \n",
    "            # Définir le tuple (étiquette POS, mot) pour cette ligne et cette colonne\n",
    "            key =  (all_tags[i], vocab[j])\n",
    "\n",
    "            # Vérifier si le tuple (étiquette POS, mot) existe en tant que clé dans emission_counts\n",
    "            if key in emission_counts.keys(): # compléter cette ligne\n",
    "        \n",
    "                # Obtenez le compte de (étiquette POS, mot) à partir du dictionnaire emission_counts\n",
    "                count = emission_counts[key]\n",
    "                \n",
    "            # Obtenez le compte de l'étiquette POS\n",
    "            count_tag = tag_counts[all_tags[i]]\n",
    "                \n",
    "            # Appliquer le lissage et stocker la valeur lissée \n",
    "            # dans la matrice d'émission B pour cette ligne et cette colonne\n",
    "            B[i,j] = (count + alpha) / (count_tag + alpha*num_words)\n",
    "    return B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "21cbcbad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246918"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['sera']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a0b26def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voir la position de la matrice à la ligne 0, colonne 0 : 0.000003716\n",
      "Voir la position de la matrice à la ligne 3, colonne 1 : 0.000000686\n",
      "[246918, 219451, 194972, 177549, 139333]\n",
      "[2, 3, 4, 5]\n",
      "               sera       nouveau          jour         entre  architecture\n",
      "ADJWH  3.715773e-06  3.715773e-06  3.715773e-06  3.715773e-06  3.715773e-06\n",
      "ADV    6.858132e-07  6.858132e-07  6.858132e-07  6.858132e-07  6.858132e-07\n",
      "ADVWH  3.621574e-06  3.621574e-06  3.621574e-06  3.621574e-06  3.621574e-06\n",
      "CC     1.132345e-06  1.132345e-06  1.132345e-06  1.132345e-06  1.132345e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "B = create_emission_matrix(alpha, tag_counts, emission_counts, list(vocab))\n",
    "\n",
    "print(f\"Voir la position de la matrice à la ligne 0, colonne 0 : {B[0,0]:.9f}\")\n",
    "print(f\"Voir la position de la matrice à la ligne 3, colonne 1 : {B[3,1]:.9f}\")\n",
    "\n",
    "\n",
    "cidx  = ['sera','nouveau','jour', 'entre', 'architecture']\n",
    "\n",
    "# Obtenez l'ID entier pour chaque mot\n",
    "cols = [vocab[a] for a in cidx]\n",
    "print(cols)\n",
    "\n",
    "# Choisissez les étiquettes POS à afficher dans un dataframe d'échantillon\n",
    "rvals =[ 'ADJWH', 'ADV', 'ADVWH', 'CC']\n",
    "\n",
    "# Pour chaque étiquette POS, obtenez le numéro de ligne à partir de la liste 'states'\n",
    "rows = [states.index(a) for a in rvals]\n",
    "print(rows)\n",
    "\n",
    "# Obtenez les émissions pour l'échantillon de mots et l'échantillon d'étiquettes POS\n",
    "B_sub = pd.DataFrame(B[np.ix_(rows,cols)], index=rvals, columns=cidx)\n",
    "print(B_sub)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379618ea",
   "metadata": {},
   "source": [
    "# Initialisation des probabilités de chemin optimal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd6fd4e",
   "metadata": {},
   "source": [
    "# initialize ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5520fbe1",
   "metadata": {},
   "source": [
    "prend en entrée une liste states de toutes les parties du discours possibles, un dictionnaire tag_counts associant chaque étiquette à son nombre respectif, une matrice de transition A de dimension (num_tags, num_tags), une matrice d'émission B de dimension (num_tags, len(vocab)), une séquence de mots corpus dont la POS doit être identifiée, et un dictionnaire vocab où les clés sont des mots du vocabulaire et la valeur est un indice.\n",
    "\n",
    "Elle initialise deux matrices, best_probs et best_paths, de dimensions (num_tags, len(corpus)). La matrice best_probs stocke les meilleures probabilités pour chaque étiquette POS à chaque position dans le corpus, tandis que la matrice best_paths stocke les chemins (c'est-à-dire les étiquettes POS précédentes) qui ont conduit à ces meilleures probabilités.\n",
    "\n",
    "La fonction parcourt chaque étiquette POS et initialise les probabilités dans best_probs en fonction de la probabilité de transition du jeton de départ vers cette étiquette POS et de la probabilité d'émission du premier mot du corpus. Si la probabilité de transition du jeton de départ vers une étiquette POS est nulle, la probabilité correspondante dans best_probs est initialisée à moins l'infini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ea4df4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(states, tag_counts, A, B, corpus, vocab):\n",
    "    '''\n",
    "    Entrées : \n",
    "        states : une liste de toutes les parties du discours possibles\n",
    "        tag_counts : un dictionnaire associant chaque étiquette à son nombre respectif\n",
    "        A : Matrice de transition de dimension (num_tags, num_tags)\n",
    "        B : Matrice d'émission de dimension (num_tags, len(vocab))\n",
    "        corpus : une séquence de mots dont la POS doit être identifiée dans une liste \n",
    "        vocab : un dictionnaire où les clés sont des mots du vocabulaire et la valeur est un indice\n",
    "    Sortie :\n",
    "        best_probs : matrice de dimension (num_tags, len(corpus)) de nombres flottants\n",
    "        best_paths : matrice de dimension (num_tags, len(corpus)) d'entiers\n",
    "    '''\n",
    "   \n",
    "    num_tags = len(tag_counts)\n",
    "    \n",
    "    # Initialiser la matrice best_probs\n",
    "    # Les étiquettes POS dans les lignes, le nombre de mots dans le corpus comme colonnes\n",
    "    best_probs = np.zeros((num_tags, len(corpus)))\n",
    "    \n",
    "    # Initialiser la matrice best_paths\n",
    "    # Les étiquettes POS dans les lignes, le nombre de mots dans le corpus comme colonnes\n",
    "    best_paths = np.zeros((num_tags, len(corpus)), dtype=int)\n",
    "    \n",
    "    # Définir le jeton de départ\n",
    "    s_idx = states.index(\"--s--\")\n",
    "    \n",
    "    # Parcourir chacune des étiquettes POS\n",
    "    for i in range(num_tags):\n",
    "        \n",
    "        # Gérer le cas spécial lorsque la transition du jeton de départ à l'étiquette POS i est nulle\n",
    "        if A[s_idx, i] == 0:\n",
    "            \n",
    "            # Initialiser best_probs à l'étiquette POS 'i', colonne 0, à moins l'infini\n",
    "            best_probs[i, 0] = float('-inf')\n",
    "        \n",
    "        # Pour tous les autres cas lorsque la transition du jeton de départ à l'étiquette POS i n'est pas nulle :\n",
    "        else:\n",
    "            # Initialiser best_probs à l'étiquette POS 'i', colonne 0\n",
    "            # Vérifier la formule dans les instructions ci-dessus\n",
    "            best_probs[i, 0] = math.log(A[s_idx, i]) + math.log(B[i, vocab[corpus[0]]])\n",
    "    \n",
    "    return best_probs, best_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1ade48cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_probs, best_paths = initialize(states, tag_counts, A, B, prep, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "57cd5fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_probs[0,0]: -19.4402\n",
      "best_paths[2,3]: 0.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"best_probs[0,0]: {best_probs[0,0]:.4f}\") \n",
    "print(f\"best_paths[2,3]: {best_paths[2,3]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6695d3be",
   "metadata": {},
   "source": [
    "# Passage en avant de l'algorithme de Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89db957c",
   "metadata": {},
   "source": [
    "# viterbi_forward ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993a8897",
   "metadata": {},
   "source": [
    "prend en entrée les matrices de transition A et d'émission B, un corpus de test test_corpus, ainsi que deux matrices préalablement initialisées best_probs et best_paths de dimension (num_tags, len(corpus)), et un dictionnaire vocab où les clés sont des mots du vocabulaire et la valeur est un indice.\n",
    "\n",
    "Elle parcourt chaque mot dans le corpus à partir du deuxième mot (indice 1) et pour chaque étiquette POS possible pour ce mot, elle calcule la probabilité de la meilleure séquence de tags jusqu'à ce mot en utilisant l'algorithme de Viterbi. Pour chaque étiquette POS, elle trouve le chemin (séquence d'étiquettes POS) qui maximise la probabilité jusqu'au mot précédent, puis elle ajoute la probabilité et l'indice de ce chemin dans les matrices best_probs et best_paths pour le mot actuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ce623184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_forward(A, B, test_corpus, best_probs, best_paths, vocab):\n",
    "    '''\n",
    "    Entrée : \n",
    "        A, B : les matrices de transition et d'émission respectivement\n",
    "        test_corpus : une liste contenant un corpus prétraité\n",
    "        best_probs : une matrice initialisée de dimension (num_tags, len(corpus))\n",
    "        best_paths : une matrice initialisée de dimension (num_tags, len(corpus))\n",
    "        vocab : un dictionnaire où les clés sont des mots du vocabulaire et la valeur est un indice \n",
    "    Sortie : \n",
    "        best_probs : une matrice complétée de dimension (num_tags, len(corpus))\n",
    "        best_paths : une matrice complétée de dimension (num_tags, len(corpus))\n",
    "    '''\n",
    "    \n",
    "    num_tags = best_probs.shape[0]\n",
    "    \n",
    "    # Parcourir chaque mot dans le corpus à partir du mot 1\n",
    "    # Rappel : le mot 0 a été initialisé dans `initialize()`\n",
    "    for i in range(1, len(test_corpus)): \n",
    "        \n",
    "        # Afficher le nombre de mots traités, tous les 5000 mots\n",
    "        if i % 5000 == 0:\n",
    "            print(\"Mots traités : {:>8}\".format(i))\n",
    "            \n",
    "        # Pour chaque étiquette POS unique que le mot actuel peut être\n",
    "        for j in range(num_tags):\n",
    "            \n",
    "            # Initialiser la meilleure probabilité pour le mot i à moins l'infini\n",
    "            best_prob_i = float(\"-inf\")\n",
    "            \n",
    "            # Initialiser le meilleur chemin pour le mot i à None\n",
    "            best_path_i = None\n",
    "\n",
    "            # Pour chaque étiquette POS que le mot précédent peut être :\n",
    "            for k in range(num_tags):\n",
    "                \n",
    "                # Calculer la probabilité =\n",
    "                # meilleures probabilités de l'étiquette POS k, mot précédent i-1 + \n",
    "                # log(probabilité de transition de POS k à POS j) + \n",
    "                # log(probabilité que l'émission de POS j soit le mot i)\n",
    "                prob = best_probs[k, i-1] + math.log(A[k, j]) + math.log(B[j, vocab[test_corpus[i]]])\n",
    "\n",
    "                # Vérifier si la probabilité de ce chemin est supérieure à\n",
    "                # la meilleure probabilité jusqu'à ce point\n",
    "                if prob > best_prob_i:\n",
    "                    \n",
    "                    # Conserver la meilleure probabilité\n",
    "                    best_prob_i = prob\n",
    "                    \n",
    "                    # Conserver l'étiquette POS du mot précédent\n",
    "                    # qui fait partie du meilleur chemin.\n",
    "                    # Enregistrer l'index (entier) associé à\n",
    "                    # l'étiquette POS de ce mot précédent\n",
    "                    best_path_i = k\n",
    "\n",
    "            # Enregistrer la meilleure probabilité pour l'étiquette POS donnée\n",
    "            # et la position du mot actuel dans le corpus\n",
    "            best_probs[j, i] = best_prob_i\n",
    "            \n",
    "            # Enregistrer l'identifiant unique entier de l'étiquette POS précédente\n",
    "            # dans la matrice best_paths, pour l'étiquette POS du mot actuel\n",
    "            # et la position du mot actuel dans le corpus.\n",
    "            best_paths[j, i] = best_path_i\n",
    "\n",
    "    return best_probs, best_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d055658a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mots traités :     5000\n",
      "Mots traités :    10000\n",
      "Mots traités :    15000\n",
      "Mots traités :    20000\n",
      "Mots traités :    25000\n",
      "Mots traités :    30000\n",
      "Mots traités :    35000\n",
      "Mots traités :    40000\n",
      "Mots traités :    45000\n",
      "Mots traités :    50000\n",
      "Mots traités :    55000\n",
      "Mots traités :    60000\n",
      "Mots traités :    65000\n",
      "Mots traités :    70000\n",
      "Mots traités :    75000\n",
      "Mots traités :    80000\n",
      "Mots traités :    85000\n",
      "Mots traités :    90000\n",
      "Mots traités :    95000\n",
      "Mots traités :   100000\n",
      "Mots traités :   105000\n",
      "Mots traités :   110000\n",
      "Mots traités :   115000\n",
      "Mots traités :   120000\n",
      "Mots traités :   125000\n",
      "Mots traités :   130000\n",
      "Mots traités :   135000\n",
      "Mots traités :   140000\n",
      "Mots traités :   145000\n",
      "Mots traités :   150000\n",
      "Mots traités :   155000\n",
      "Mots traités :   160000\n",
      "Mots traités :   165000\n",
      "Mots traités :   170000\n",
      "Mots traités :   175000\n",
      "Mots traités :   180000\n",
      "Mots traités :   185000\n",
      "Mots traités :   190000\n",
      "Mots traités :   195000\n",
      "Mots traités :   200000\n",
      "Mots traités :   205000\n",
      "Mots traités :   210000\n",
      "Mots traités :   215000\n",
      "Mots traités :   220000\n",
      "Mots traités :   225000\n",
      "Mots traités :   230000\n",
      "Mots traités :   235000\n",
      "Mots traités :   240000\n",
      "Mots traités :   245000\n",
      "Mots traités :   250000\n",
      "Mots traités :   255000\n",
      "Mots traités :   260000\n",
      "Mots traités :   265000\n",
      "Mots traités :   270000\n",
      "Mots traités :   275000\n",
      "Mots traités :   280000\n",
      "Mots traités :   285000\n",
      "Mots traités :   290000\n",
      "Mots traités :   295000\n",
      "Mots traités :   300000\n",
      "Mots traités :   305000\n",
      "Mots traités :   310000\n",
      "Mots traités :   315000\n",
      "Mots traités :   320000\n",
      "Mots traités :   325000\n",
      "Mots traités :   330000\n",
      "Mots traités :   335000\n",
      "Mots traités :   340000\n",
      "Mots traités :   345000\n",
      "Mots traités :   350000\n",
      "Mots traités :   355000\n",
      "Mots traités :   360000\n",
      "Mots traités :   365000\n",
      "Mots traités :   370000\n",
      "Mots traités :   375000\n",
      "Mots traités :   380000\n",
      "Mots traités :   385000\n",
      "Mots traités :   390000\n",
      "Mots traités :   395000\n",
      "Mots traités :   400000\n",
      "Mots traités :   405000\n",
      "Mots traités :   410000\n",
      "Mots traités :   415000\n",
      "Mots traités :   420000\n",
      "Mots traités :   425000\n",
      "Mots traités :   430000\n",
      "Mots traités :   435000\n",
      "Mots traités :   440000\n",
      "Mots traités :   445000\n",
      "Mots traités :   450000\n",
      "Mots traités :   455000\n",
      "Mots traités :   460000\n",
      "Mots traités :   465000\n",
      "Mots traités :   470000\n",
      "Mots traités :   475000\n",
      "Mots traités :   480000\n",
      "Mots traités :   485000\n",
      "Mots traités :   490000\n",
      "Mots traités :   495000\n",
      "Mots traités :   500000\n",
      "Mots traités :   505000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_probs, best_paths = viterbi_forward(A, B, prep, best_probs, best_paths, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5237efa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_probs[0,1]: -33.3522\n",
      "best_probs[0,4]: -49.1182\n"
     ]
    }
   ],
   "source": [
    "# tester la fonction\n",
    "print(f\"best_probs[0,1]: {best_probs[0,1]:.4f}\") \n",
    "print(f\"best_probs[0,4]: {best_probs[0,4]:.4f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7080343a",
   "metadata": {},
   "source": [
    "# Passage en arrière de l'algorithme de Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7ad1b0",
   "metadata": {},
   "source": [
    "# viterbi_backward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3442c136",
   "metadata": {},
   "source": [
    "prend en entrée les matrices best_probs et best_paths résultantes de l'algorithme de Viterbi appliqué dans le sens direct, ainsi que le corpus de mots corpus et la liste de toutes les étiquettes possibles states.\n",
    "\n",
    "Elle retourne le meilleur chemin prédit en parcourant les matrices best_probs et best_paths en sens inverse, à partir du dernier mot dans le corpus jusqu'au premier. Pour chaque mot, elle récupère l'index de l'étiquette POS prédite avec la probabilité la plus élevée à partir de la matrice best_probs et utilise cet index pour récupérer l'étiquette POS prédite à partir de la matrice best_paths. Elle stocke ensuite cette étiquette POS prédite dans le tableau pred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "26289eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_backward(best_probs, best_paths, corpus, states):\n",
    "    '''\n",
    "    Cette fonction retourne le meilleur chemin.\n",
    "    '''\n",
    "    # Obtenir le nombre de mots dans le corpus\n",
    "    # qui est également le nombre de colonnes dans best_probs, best_paths\n",
    "    m = best_paths.shape[1] \n",
    "    \n",
    "    # Initialiser le tableau z, de la même longueur que le corpus\n",
    "    z = [None] * m\n",
    "    \n",
    "    # Obtenir le nombre d'étiquettes POS uniques\n",
    "    num_tags = best_probs.shape[0]\n",
    "    \n",
    "    # Initialiser la meilleure probabilité pour le dernier mot\n",
    "    best_prob_for_last_word = float('-inf')\n",
    "    \n",
    "    # Initialiser le tableau pred, de la même longueur que le corpus\n",
    "    pred = [None] * m\n",
    "    \n",
    "    # Étape 1\n",
    "    \n",
    "    # Parcourir chaque étiquette POS pour le dernier mot (dernière colonne de best_probs)\n",
    "    # afin de trouver la ligne (identifiant entier de l'étiquette POS) \n",
    "    # avec la probabilité la plus élevée pour le dernier mot\n",
    "    for k in range(num_tags):\n",
    "        \n",
    "        # Si la probabilité de l'étiquette POS à la ligne k \n",
    "        # est meilleure que la meilleure probabilité précédente pour le dernier mot :\n",
    "        if best_probs[k, -1] > best_prob_for_last_word:\n",
    "            \n",
    "            # Stocker la nouvelle meilleure probabilité pour le dernier mot\n",
    "            best_prob_for_last_word = best_probs[k, -1]\n",
    "    \n",
    "            # Stocker l'identifiant unique de l'étiquette POS\n",
    "            # qui est également le numéro de ligne dans best_probs\n",
    "            z[m - 1] = k\n",
    "            \n",
    "    # Convertir l'étiquette POS prédite du dernier mot\n",
    "    # de son identifiant entier unique en la représentation sous forme de chaîne\n",
    "    # en utilisant le dictionnaire 'states'\n",
    "    # stocker ceci dans le tableau 'pred' pour le dernier mot\n",
    "    pred[m - 1] = states[k]\n",
    "    \n",
    "    # Étape 2\n",
    "    \n",
    "    # Trouver les meilleures étiquettes POS en parcourant en arrière les best_paths\n",
    "    # Du dernier mot dans le corpus au 0ème mot dans le corpus\n",
    "    for i in range(len(corpus) - 1, -1, -1):\n",
    "        \n",
    "        # Récupérer l'identifiant entier unique de\n",
    "        # l'étiquette POS pour le mot à la position 'i' dans le corpus\n",
    "        pos_tag_for_word_i = best_paths[np.argmax(best_probs[:, i]), i]\n",
    "        \n",
    "        # Dans best_paths, aller à la ligne représentant l'étiquette POS du mot i\n",
    "        # et la colonne représentant la position du mot dans le corpus\n",
    "        # pour récupérer l'étiquette POS prédite pour le mot à la position i-1 dans le corpus\n",
    "        z[i - 1] = best_paths[pos_tag_for_word_i, i]\n",
    "        \n",
    "        # Obtenir l'étiquette POS du mot précédent sous forme de chaîne\n",
    "        # Utiliser le dictionnaire 'states',\n",
    "        # où la clé est l'identifiant entier unique de l'étiquette POS,\n",
    "        # et la valeur est la représentation de chaîne de cette étiquette POS\n",
    "        pred[i - 1] = states[pos_tag_for_word_i]\n",
    "        \n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2b40d704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction for pred[-7:m-1] is: \n",
      " ['hauteur', 'se', 'sont', 'échappées', 'du', 'véhicule'] \n",
      " ['NC', 'CLR', 'V', 'VPP', 'P+D', 'NC'] \n",
      "\n",
      "The prediction for pred[0:8] is: \n",
      " ['DET', 'NC', 'PONCT', 'DET', 'NC', 'P', 'DET'] \n",
      " ['Ce', 'vendredi', ',', 'quatre', 'matchs', 'de', 'la']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred = viterbi_backward(best_probs, best_paths, prep, states)\n",
    "m=len(pred)\n",
    "print('The prediction for pred[-7:m-1] is: \\n', prep[-7:m-1], \"\\n\", pred[-7:m-1], \"\\n\")\n",
    "print('The prediction for pred[0:8] is: \\n', pred[0:7], \"\\n\", prep[0:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4a84fbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The third word is: quatre\n",
      "Your prediction is: DET\n",
      "Your corresponding label y is:  quatre_DET\n"
     ]
    }
   ],
   "source": [
    "print('The third word is:', prep[3])\n",
    "print('Your prediction is:', pred[3])\n",
    "print('Your corresponding label y is: ', y[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6247113",
   "metadata": {},
   "source": [
    "# Calcul de l'exactitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5dca12",
   "metadata": {},
   "source": [
    "# compute_accuracy ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446b2760",
   "metadata": {},
   "source": [
    "prend en entrée deux listes : pred, contenant les parties du discours prédites, et y, contenant les lignes où chaque mot est suivi de son étiquette (séparés par un '\\t').\n",
    "\n",
    "Elle calcule le taux de précision en comparant les parties du discours prédites avec les étiquettes réelles. Pour chaque prédiction et étiquette réelle, elle vérifie si elles correspondent, puis incrémente le compteur num_correct en conséquence. Elle compte également le nombre total d'exemples valides avec des étiquettes. Enfin, elle calcule le taux de précision en divisant le nombre de prédictions correctes par le nombre total d'exemples valides et retourne ce taux de précision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "28b70246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(pred, y):\n",
    "    '''\n",
    "    Entrée : \n",
    "        pred : une liste des parties du discours prédites\n",
    "        y : une liste de lignes où chaque mot est séparé par un '\\t' (c'est-à-dire mot \\t étiquette)\n",
    "    Sortie : \n",
    "        accuracy : le taux de précision calculé comme le nombre de prédictions correctes divisé par le nombre total de prédictions valides\n",
    "    '''\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Combinez ensemble la prédiction et les étiquettes\n",
    "    for prediction, y in zip(pred, y):\n",
    "        \n",
    "        # Séparez l'étiquette en mot et en étiquette POS\n",
    "        mot_etiquette_tuple = y.split('_')\n",
    "        \n",
    "        # Vérifiez s'il y a effectivement un mot et une étiquette\n",
    "        # ni plus ni moins de 2 éléments\n",
    "        if len(mot_etiquette_tuple) != 2:\n",
    "            continue \n",
    "\n",
    "        # Stockez le mot et l'étiquette séparément\n",
    "        mot, etiquet = mot_etiquette_tuple\n",
    "        \n",
    "        # Vérifiez si l'étiquette POS correspond à la prédiction\n",
    "        if prediction == etiquet:\n",
    "            \n",
    "            # Comptez le nombre de fois où la prédiction\n",
    "            # et l'étiquette correspondent\n",
    "            num_correct += 1\n",
    "            \n",
    "        # Gardez une trace du nombre total d'exemples (ayant des étiquettes valides)\n",
    "        total += 1\n",
    "        \n",
    "   \n",
    "    accuracy = num_correct / total\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44fc8b8",
   "metadata": {},
   "source": [
    "# Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5e7bfc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Viterbi algorithm is 0.8863\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy of the Viterbi algorithm is {compute_accuracy(pred, y):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36560742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7318ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e484d07c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
